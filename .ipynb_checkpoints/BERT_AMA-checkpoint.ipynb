{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_AMA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTciJ07Rn7l-",
        "outputId": "76b76fce-a29f-42b6-f0ee-71af59ff9c3e"
      },
      "source": [
        "!pip install wikipedia\r\n",
        "!pip install googlesearch-python\r\n",
        "!pip install requests\r\n",
        "!pip install transformers==4.2.2\r\n",
        "!pip install tensorflow==2.4.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.24.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.9.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.25.9)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4->wikipedia) (2.0.1)\n",
            "Requirement already satisfied: googlesearch-python in /usr/local/lib/python3.6/dist-packages (2020.0.2)\n",
            "Requirement already satisfied: certifi==2020.6.20 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (2020.6.20)\n",
            "Requirement already satisfied: soupsieve==2.0.1 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (2.0.1)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (3.0.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.1 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (4.9.1)\n",
            "Requirement already satisfied: requests==2.24.0 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (2.24.0)\n",
            "Requirement already satisfied: urllib3==1.25.9 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (1.25.9)\n",
            "Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (0.0.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.6/dist-packages (from googlesearch-python) (2.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.24.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.25.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
            "Requirement already satisfied: transformers==4.2.2 in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (20.9)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (2.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.2) (0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.2) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.2) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.2.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.2.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.2.2) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.2.2) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.2) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.2) (1.25.9)\n",
            "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (53.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.24.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.25.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD3ZjdQuErYJ"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import json\r\n",
        "import itertools\r\n",
        "\r\n",
        "import wikipedia\r\n",
        "import requests\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from concurrent.futures import ThreadPoolExecutor\r\n",
        "from pprint import pprint\r\n",
        "from googlesearch import search\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "from transformers import TFAutoModel, AutoTokenizer, AutoConfig"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A8A8K4HIfdi"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', use_fast=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ6j0_JnDebA"
      },
      "source": [
        "BASE_DIR = 'drive/MyDrive'\r\n",
        "DO_TRAIN = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-XwtJs9IjN9"
      },
      "source": [
        "class QARecord:\r\n",
        "    def __init__(self, question, context, is_impossible, answer_text=None, answer_start=-1):\r\n",
        "        self.question = question\r\n",
        "        self.context = context\r\n",
        "        self.is_impossible = is_impossible\r\n",
        "        self.answer_text = answer_text\r\n",
        "        self.answer_start = answer_start\r\n",
        "        if not is_impossible:\r\n",
        "            self.answer_end = answer_start + len(answer_text)\r\n",
        "        else:\r\n",
        "            self.answer_end = -1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXt-HMorFDi7"
      },
      "source": [
        "class QADataset:\r\n",
        "    SQUAD_DIR = os.path.join(BASE_DIR, 'datasets/squad20')\r\n",
        "    \r\n",
        "    def __init__(self):\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def _record_generator(self, filename):\r\n",
        "        with open(os.path.join(self.SQUAD_DIR, filename)) as f:\r\n",
        "            d = json.load(f)\r\n",
        "        for x in d['data']:\r\n",
        "            for p in x['paragraphs']:\r\n",
        "                context = p['context']\r\n",
        "                qas = p['qas']\r\n",
        "                for q in qas:\r\n",
        "                    question = q['question']\r\n",
        "                    is_impossible = q['is_impossible']\r\n",
        "                    answer, answer_start = None, -1\r\n",
        "\r\n",
        "                    if not is_impossible:\r\n",
        "                        answer = q['answers'][0]['text']\r\n",
        "                        answer_start = q['answers'][0]['answer_start']\r\n",
        "\r\n",
        "                    yield QARecord(question, context, is_impossible, answer, answer_start)\r\n",
        "    \r\n",
        "    def train(self, **kwargs):\r\n",
        "        return self._make(self._record_generator('train-v2.0.json'), **kwargs)\r\n",
        "    \r\n",
        "    def dev(self, **kwargs):\r\n",
        "        return self._make(self._record_generator('dev-v2.0.json'), **kwargs)\r\n",
        "    \r\n",
        "    def test(self, **kwargs):\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def predict(self, q, c):\r\n",
        "        return self._make([QARecord(q, c, True)])\r\n",
        "    \r\n",
        "    def _make(self, records, shuffle=False, drop_remainder=False):\r\n",
        "        MAX_LENGTH = 128\r\n",
        "        def generator():\r\n",
        "            for record in records:\r\n",
        "                encoding = tokenizer.encode_plus(\r\n",
        "                    record.question,\r\n",
        "                    record.context,\r\n",
        "                    max_length=MAX_LENGTH,\r\n",
        "                    truncation=True,\r\n",
        "                    padding='max_length',\r\n",
        "                    return_offsets_mapping=True,\r\n",
        "                    return_overflowing_tokens=True,\r\n",
        "                    stride=16\r\n",
        "                )\r\n",
        "\r\n",
        "                input_ids = encoding['input_ids']\r\n",
        "                attention_masks = encoding['attention_mask']\r\n",
        "                token_type_ids = encoding.get('token_type_ids', itertools.repeat(None))\r\n",
        "                offset_mappings = encoding['offset_mapping']\r\n",
        "\r\n",
        "                for input_id, attention_mask, token_type_id, offset_mapping in zip(input_ids, attention_masks, token_type_ids, offset_mappings):\r\n",
        "                    if record.is_impossible:\r\n",
        "                        start, end = 0, 0\r\n",
        "                    else:\r\n",
        "                        try:\r\n",
        "                            start = [i for i, x in enumerate(offset_mapping) if x[0]==record.answer_start][0]\r\n",
        "                            end = [i for i, x in enumerate(offset_mapping) if x[1]==record.answer_end][0]\r\n",
        "                        except IndexError:\r\n",
        "                            start, end = 0, 0\r\n",
        "\r\n",
        "                    yield {\r\n",
        "                        'input_ids': input_id,\r\n",
        "                        'attention_mask': attention_mask,\r\n",
        "                        #'token_type_ids': token_type_id,\r\n",
        "                    }, [start, end]\r\n",
        "\r\n",
        "        dataset = tf.data.Dataset.from_generator(\r\n",
        "            generator,\r\n",
        "            output_types=( \r\n",
        "                {\r\n",
        "                    'input_ids': tf.int32,\r\n",
        "                    'attention_mask': tf.int32,\r\n",
        "                    #'token_type_ids': tf.int32,\r\n",
        "                },\r\n",
        "                tf.int32\r\n",
        "            ),\r\n",
        "            output_shapes=(\r\n",
        "                {\r\n",
        "                    'input_ids': (MAX_LENGTH,),\r\n",
        "                    'attention_mask': (MAX_LENGTH,),\r\n",
        "                    #'token_type_ids': (MAX_LENGTH,)\r\n",
        "                },\r\n",
        "                (2,)\r\n",
        "            )\r\n",
        "        )\r\n",
        "\r\n",
        "        if shuffle:\r\n",
        "            dataset.shuffle(10000)\r\n",
        "        return dataset.batch(32, drop_remainder=drop_remainder).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvtdzLtF5b1"
      },
      "source": [
        "class QAModel(tf.keras.Model):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        config = AutoConfig.from_pretrained(\r\n",
        "            'distilbert-base-uncased', output_attentions=False, output_hidden_states=False\r\n",
        "        )\r\n",
        "        self.bert = TFAutoModel.from_pretrained('distilbert-base-uncased', config=config) \r\n",
        "        self.dropout = tf.keras.layers.Dropout(0.1)\r\n",
        "        self.dense = tf.keras.layers.Dense(2, dtype=tf.float32)\r\n",
        "    \r\n",
        "    def call(self, inputs, training=False):\r\n",
        "        res = self.bert(inputs, training=training)\r\n",
        "        seq = res['last_hidden_state']\r\n",
        "        x = self.dropout(seq)\r\n",
        "        x = self.dense(x)\r\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImcKztriFRSV"
      },
      "source": [
        "def QAloss(labels, logits):\r\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "        from_logits=True\r\n",
        "    )\r\n",
        "    start_logits, end_logits = logits[:, :, 0], logits[:, :, 1]\r\n",
        "    start_loss = loss_fn(labels[:, 0], start_logits)\r\n",
        "    end_loss = loss_fn(labels[:, 1], end_logits)\r\n",
        "    return (start_loss + end_loss)/2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsRUKj-GFX4c"
      },
      "source": [
        "model_checkpoint_callback  = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    os.path.join(BASE_DIR, 'models/QA/QAModel'),\r\n",
        "    monitor='val_loss',\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=True, mode='auto'\r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z3FxSlKFZSN"
      },
      "source": [
        "dataset = QADataset()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGTbg2GpFa3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e19520-9aa0-4228-ef2d-f78a828ad970"
      },
      "source": [
        "model = QAModel()\r\n",
        "model.compile(\r\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\r\n",
        "    loss=QAloss,\r\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSISCcbhD8ty"
      },
      "source": [
        "if DO_TRAIN:\r\n",
        "    history = model.fit(\r\n",
        "      dataset.train(shuffle=True, drop_remainder=True), epochs=1, validation_data=dataset.dev(),\r\n",
        "      callbacks=[model_checkpoint_callback]\r\n",
        "    )\r\n",
        "else:\r\n",
        "    model.load_weights(os.path.join(BASE_DIR, 'models/QA/QAModel'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ganCjHNWFe-X"
      },
      "source": [
        "def get_url_content(url):\r\n",
        "    try:\r\n",
        "        return requests.get(url, timeout=10).text\r\n",
        "    except Exception as e:\r\n",
        "        pass\r\n",
        "\r\n",
        "def get_context(question, source='wiki', top_n=5):\r\n",
        "    if source == 'wiki':\r\n",
        "        for st in wikipedia.search(question)[:top_n]:\r\n",
        "            yield wikipedia.page(st).content\r\n",
        "    elif source == 'google':\r\n",
        "        urls = search(question)[:top_n]\r\n",
        "        with ThreadPoolExecutor() as pool:\r\n",
        "            for text in list(pool.map(get_url_content, urls)):\r\n",
        "                if text:\r\n",
        "                    soup = BeautifulSoup(text)\r\n",
        "                    yield re.sub(r'[\\n]+', '\\n', soup.get_text())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euygo6MVFgF9"
      },
      "source": [
        "def _get_offset(input_ids):\r\n",
        "    sep = np.where(input_ids == 102)[0]\r\n",
        "    offset = sep[0] + 1\r\n",
        "    try:\r\n",
        "        till = sep[1]\r\n",
        "    except IndexError:\r\n",
        "        till = len(input_ids)\r\n",
        "    return offset, till\r\n",
        "\r\n",
        "def _get_answer(dp, top_n=1):\r\n",
        "    \r\n",
        "    dp_a = dp.take(-1)\r\n",
        "    p_a = model.predict(dp_a)\r\n",
        "    \r\n",
        "    for idx, d in enumerate(iter(dp.unbatch().batch(1))):\r\n",
        "        p = p_a[[idx], :, :]\r\n",
        "        \r\n",
        "        top_n_temp = top_n\r\n",
        "        input_ids = d[0]['input_ids'].numpy()[0]\r\n",
        "\r\n",
        "        offset, till = _get_offset(input_ids)\r\n",
        "\r\n",
        "        start_proba, end_proba = p[:, :, 0][0], p[:, :, 1][0]\r\n",
        "        \r\n",
        "        mask = [0 if offset <= x < till else 1e-8 for x in range(len(start_proba))]\r\n",
        "        mask[0] = 0\r\n",
        "        \r\n",
        "        start_proba = start_proba + mask\r\n",
        "        end_proba = end_proba + mask\r\n",
        "        \r\n",
        "        start_proba = tf.nn.softmax(start_proba).numpy()\r\n",
        "        end_proba = tf.nn.softmax(end_proba).numpy()\r\n",
        "        \r\n",
        "        no_answer_score = start_proba[0] * end_proba[0]\r\n",
        "        \r\n",
        "        start_proba = start_proba[offset:till]\r\n",
        "        end_proba = end_proba[offset:till]\r\n",
        "        \r\n",
        "        results = []\r\n",
        "        \r\n",
        "        for i,s in enumerate(start_proba):\r\n",
        "            for j,e in enumerate(end_proba):\r\n",
        "                if i>j:\r\n",
        "                    continue\r\n",
        "                results.append({\r\n",
        "                    'start': offset + i,\r\n",
        "                    'end': offset + j,\r\n",
        "                    'score': s*e\r\n",
        "                })\r\n",
        "        \r\n",
        "        results = sorted(results, key=lambda x: x['score'], reverse=True)\r\n",
        "        results = [x for x in results if x['score']>no_answer_score]\r\n",
        "        \r\n",
        "        for r in results:\r\n",
        "            r['text'] = tokenizer.decode(input_ids[r['start']:r['end']+1])\r\n",
        "            r['context'] = tokenizer.decode(input_ids[r['start']-15:r['end']+1+15])\r\n",
        "\r\n",
        "        yield results[:top_n]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLKgm0YFFhQv"
      },
      "source": [
        "def bert_ama(question, source='google', max_urls=5, top_n=None, thresh=0):\r\n",
        "    \"\"\"\r\n",
        "    question: The question you want to ask\r\n",
        "    source: wiki or google. No need to change. google works better.\r\n",
        "    max_urls: Maximum number of search results where we look for answers.\r\n",
        "    top_n: Number of esults returned.\r\n",
        "    thresh: Only answers which have a score greater than thresh will be consider further.\r\n",
        "    \"\"\"\r\n",
        "    results = []\r\n",
        "    for context in get_context(question, source, top_n=max_urls):\r\n",
        "        dp = dataset.predict(question, context)\r\n",
        "\r\n",
        "        for result in _get_answer(dp, top_n):\r\n",
        "            results.extend(result)\r\n",
        "    \r\n",
        "    df = pd.DataFrame(results)\r\n",
        "    if df.empty:\r\n",
        "      return df\r\n",
        "\r\n",
        "    def scorer(arr):\r\n",
        "        \"\"\"Calculate final score for a givne answer\r\n",
        "        \r\n",
        "        Total score = A[0] + A[1]/4 + A[2]/9 + A[3]/16 ....\r\n",
        "        A[i] is the i'th score in descending order for a particuar answer \r\n",
        "        \"\"\"\r\n",
        "        return sum(\r\n",
        "            x/i for i,x in enumerate(sorted(arr, reverse=True), start=1)\r\n",
        "        )\r\n",
        "  \r\n",
        "    df = df.sort_values(by='score', ascending=False)\r\n",
        "    if thresh:\r\n",
        "      df = df[df['score'] > thresh]\r\n",
        "    df = df.groupby('text').agg({\r\n",
        "        'score': scorer, 'context': list\r\n",
        "    })\r\n",
        "    df = df.reset_index()\r\n",
        "    df = df.sort_values(by='score', ascending=False)\r\n",
        "    if top_n:\r\n",
        "        df = df.head(top_n)\r\n",
        "    return df"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "8K8cAd9HZHTa",
        "outputId": "5969ea87-2443-4b04-d3ef-4dbfe5ad5c69"
      },
      "source": [
        "bert_ama('Who is the founder of google?', source='google', max_urls=5, top_n=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>larry page</td>\n",
              "      <td>0.638208</td>\n",
              "      <td>[— about a month after donald j. trump was ele...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         text     score                                            context\n",
              "2  larry page  0.638208  [— about a month after donald j. trump was ele..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRo-albfNr7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b79650d5-d8d9-4cba-cf93-151f7538a6d7"
      },
      "source": [
        "bert_ama('What is the chemical formula of benzene?', source='google', max_urls=5, top_n=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c6h6</td>\n",
              "      <td>1.329239</td>\n",
              "      <td>[is as shown in the figure below. the chemical...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   text     score                                            context\n",
              "1  c6h6  1.329239  [is as shown in the figure below. the chemical..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "l_DJfuNU7kiG",
        "outputId": "bb5343ed-d52d-4675-f54b-f3ba76a07358"
      },
      "source": [
        "bert_ama('What is the capital of India?', source='google', max_urls=5, top_n=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new delhi</td>\n",
              "      <td>1.207674</td>\n",
              "      <td>[; malvika singh ; rudrangshu mukherjee ( 2009...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        text     score                                            context\n",
              "1  new delhi  1.207674  [; malvika singh ; rudrangshu mukherjee ( 2009..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ayml3YM_9aER",
        "outputId": "4f805377-ae01-425b-d5f4-d1cadc884009"
      },
      "source": [
        "bert_ama('How many carbon atoms does buckminsterfullerene have?', source='google', max_urls=5, top_n=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sixty</td>\n",
              "      <td>0.801346</td>\n",
              "      <td>[is slippery and has a low melting point. buck...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    text     score                                            context\n",
              "1  sixty  0.801346  [is slippery and has a low melting point. buck..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "bs_GCq_9-Kko",
        "outputId": "cb92a82e-785f-4f6b-e633-f6d18a176228"
      },
      "source": [
        "bert_ama('when is the independence day celebrated in india?', source='google', max_urls=5, top_n=1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15th of august</td>\n",
              "      <td>1.086717</td>\n",
              "      <td>[independence day of india, which is celebrate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             text     score                                            context\n",
              "4  15th of august  1.086717  [independence day of india, which is celebrate..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "FeYX3lifAc_T",
        "outputId": "13305d5a-5d59-4c69-96b5-b6f855a5ce70"
      },
      "source": [
        "bert_ama('what is the answer to the ultimate question of life, the universe, and everything?', source='google', max_urls=5, top_n=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>1.347246</td>\n",
              "      <td>[slang dictionary 42 [ fawr - tee too ] what d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  text     score                                            context\n",
              "1   42  1.347246  [slang dictionary 42 [ fawr - tee too ] what d..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}